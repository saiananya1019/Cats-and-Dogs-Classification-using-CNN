{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw5YcYECXp-S",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# cat and dog classification using CNN\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os, cv2\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# loading the dataset\n",
        "dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)\n",
        "class_names = info.features['label'].names\n",
        "\n",
        "\n",
        "\n",
        "for i, example in enumerate(dataset['train']):\n",
        "  image, label = example\n",
        "  save_dir = './cats_vs_dogs/train/{}'.format(class_names[label])\n",
        "  os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "  filename = save_dir + '/' + \"{}_{}.jpg\".format(class_names[label], i)\n",
        "  tf.keras.preprocessing.image.save_img(filename, image.numpy())\n",
        "  print(filename)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread(\"/content/cats_vs_dogs/train/cat/cat_100.jpg\")\n",
        "cv2_imshow(img)\n",
        "\n",
        "img1 = cv2.imread(\"/content/cats_vs_dogs/train/dog/dog_1.jpg\")\n",
        "cv2_imshow(img1)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.10, horizontal_flip=True)\n",
        "\n",
        "print(datagen)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/cats_vs_dogs/train', target_size=(150, 150), batch_size=32, class_mode='binary', subset='training')\n",
        "\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/cats_vs_dogs/train', target_size=(150, 150), batch_size=32, class_mode='binary', subset='validation')\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Create a new Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add all layers at once\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# The problematic lines were removed from here\n",
        "# model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(150,150,3)))\n",
        "# model.add(MaxPooling2D(2))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
        "# model.add(MaxPooling2D(2))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# model.add(Conv2D(128,kernel_size=3,activation='relu'))\n",
        "# model.add(MaxPooling2D(2))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(512,activation='relu'))\n",
        "# model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "j75AuasURrQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop=EarlyStopping(monitor='val_loss',patience=3, restore_best_weights=True)\n",
        "history=model.fit(train_generator,epochs=10,validation_data=validation_generator,callbacks=[early_stop]) # Changed early_stopping to early_stop\n",
        "history.history\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_generator,epochs=10,validation_data=validation_generator,callbacks=[early_stop])\n",
        "history.history\n"
      ],
      "metadata": {
        "id": "xKKWdFoDR42O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 1: Visualize Training Results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract accuracy and loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Training vs Validation Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy', color='blue')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Plot Training vs Validation Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss', color='blue')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# ‚úÖ Step 2: Save the Model\n",
        "model.save(\"cats_vs_dogs_classifier.h5\")\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# ‚úÖ Step 3: Load & Test Model with a New Image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(150, 150))  # Resize image\n",
        "    img_array = image.img_to_array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    if prediction[0][0] > 0.5:\n",
        "        print(f\"Predicted: üê∂ Dog ({prediction[0][0]:.2f} confidence)\")\n",
        "    else:\n",
        "        print(f\"Predicted: üê± Cat ({1 - prediction[0][0]:.2f} confidence)\")\n",
        "\n",
        "    # Show the image\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ‚úÖ Step 4: Test the Model with a Sample Image\n",
        "# Change path accordingly to test a cat or dog image\n",
        "predict_image('/content/cats_vs_dogs/train/cat/cat_100.jpg')\n",
        "\n",
        "# ‚úÖ Step 5: Load the Saved Model & Test Again\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model(\"cats_vs_dogs_classifier.h5\")\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Test Again with a Different Image\n",
        "predict_image('/content/cats_vs_dogs/train/dog/dog_10024.jpg')\n"
      ],
      "metadata": {
        "id": "6F4VBHqjSIvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # This will open a file upload dialog\n"
      ],
      "metadata": {
        "id": "R_F_5J5eactX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get the uploaded file name\n",
        "image_filename = list(uploaded.keys())[0]\n",
        "image_path = os.path.join(\"/content/\", image_filename)\n",
        "\n",
        "# Predict the uploaded image\n",
        "predict_image(image_path)"
      ],
      "metadata": {
        "id": "kbZ_NGorcQnR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}